{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb1681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517df4f",
   "metadata": {},
   "source": [
    "\n",
    "# Read single CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307ba0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_file_acc=pd.read_csv(\"C:\\data science\\MetaMotion\\A-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Accelerometer_12.500Hz_1.4.4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141b3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_file_gyr=pd.read_csv(\"C:\\data science\\MetaMotion\\A-bench-heavy_MetaWear_2019-01-14T14.22.49.165_C42732BE255C_Gyroscope_25.000Hz_1.4.4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b32811",
   "metadata": {},
   "source": [
    "# List all data in data/raw/MetaMotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb4f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=glob(\"C:\\data science\\MetaMotion\\*.csv\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73212de6",
   "metadata": {},
   "source": [
    "# Extract features from filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897c214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A\n",
      "bench\n",
      "heavy\n"
     ]
    }
   ],
   "source": [
    "data_path= \"C:\\data science\\MetaMotion\\\\\"\n",
    "f=files[0]\n",
    "participant =f.split(\"-\")[0].replace(data_path,\" \")\n",
    "print (participant)\n",
    "label=f.split(\"-\")[1]\n",
    "print(label)\n",
    "category=f.split(\"-\")[2].rstrip(\"123\").rstrip(\"_MetaWear_2019\")\n",
    "print(category)\n",
    "\n",
    "df=pd.read_csv(f)\n",
    "df[\"participant\"]=participant\n",
    "df[\"label\"]=label\n",
    "df[\"category\"]=category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe88b5a",
   "metadata": {},
   "source": [
    "# Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b68a0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gyr_df=pd.DataFrame()\n",
    "acc_df=pd.DataFrame()\n",
    "acc_set=1\n",
    "gyr_set=1\n",
    "for f in files :\n",
    "    participant =f.split(\"-\")[0].replace(data_path,\" \")\n",
    "\n",
    "    label=f.split(\"-\")[1]\n",
    "\n",
    "    category=f.split(\"-\")[2].rstrip(\"123\").rstrip(\"_MetaWear_2019\")\n",
    "    df=pd.read_csv(f)\n",
    "    df[\"participant\"]=participant\n",
    "    df[\"label\"]=label\n",
    "    df[\"category\"]=category\n",
    "#split in diff for acc and gyr\n",
    "    if \"Accelerometer\" in f:\n",
    "        df[\"set\"]=acc_set\n",
    "        acc_set+=1\n",
    "        acc_df=pd.concat([acc_df,df])\n",
    "    if \"Gyroscope\"in f:\n",
    "        df[\"set\"]=gyr_set\n",
    "        gyr_set+=1\n",
    "        gyr_df=pd.concat([gyr_df,df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ec0da",
   "metadata": {},
   "source": [
    "# Working with datetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8a6011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23578 entries, 0 to 241\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   epoch (ms)    23578 non-null  int64  \n",
      " 1   time (01:00)  23578 non-null  object \n",
      " 2   elapsed (s)   23578 non-null  float64\n",
      " 3   x-axis (g)    23578 non-null  float64\n",
      " 4   y-axis (g)    23578 non-null  float64\n",
      " 5   z-axis (g)    23578 non-null  float64\n",
      " 6   participant   23578 non-null  object \n",
      " 7   label         23578 non-null  object \n",
      " 8   category      23578 non-null  object \n",
      " 9   set           23578 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(4)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the data structure\n",
    "acc_df.info()\n",
    "\n",
    "# Convert epoch milliseconds to datetime objects\n",
    "pd.to_datetime(df[\"epoch (ms)\"], unit=\"ms\")\n",
    "\n",
    "# Set the datetime as the index for both sensor DataFrames\n",
    "acc_df.index = pd.to_datetime(acc_df[\"epoch (ms)\"], unit=\"ms\")\n",
    "gyr_df.index = pd.to_datetime(gyr_df[\"epoch (ms)\"], unit=\"ms\")\n",
    "\n",
    "# Delete redundant time columns to save memory\n",
    "del acc_df[\"epoch (ms)\"]\n",
    "del acc_df[\"time (01:00)\"]\n",
    "del acc_df[\"elapsed (s)\"]\n",
    "\n",
    "del gyr_df[\"epoch (ms)\"]\n",
    "del gyr_df[\"time (01:00)\"]\n",
    "del gyr_df[\"elapsed (s)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fbfe4",
   "metadata": {},
   "source": [
    "# Turn into function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0211eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"C:\\data science\\MetaMotion/*.csv\")\n",
    "\n",
    "def read_data_from_files(files):\n",
    "    acc_df = pd.DataFrame()\n",
    "    gyr_df = pd.DataFrame()\n",
    "\n",
    "    acc_set = 1\n",
    "    gyr_set = 1\n",
    "\n",
    "    for f in files:\n",
    "        # Extract metadata from filename\n",
    "        participant = f.split(\"-\")[0].replace(data_path, \"\")\n",
    "        label = f.split(\"-\")[1]\n",
    "        category = f.split(\"-\")[2].rstrip(\"123\").rstrip(\"_MetaWear_2019\")\n",
    "\n",
    "        # Load the individual CSV\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "        # Add metadata columns to the dataframe\n",
    "        df[\"participant\"] = participant\n",
    "        df[\"label\"] = label\n",
    "        df[\"category\"] = category\n",
    "\n",
    "        # Separate and label sets for Accelerometer data\n",
    "        if \"Accelerometer\" in f:\n",
    "            df[\"set\"] = acc_set\n",
    "            acc_set += 1\n",
    "            acc_df = pd.concat([acc_df, df])\n",
    "\n",
    "        # Separate and label sets for Gyroscope data\n",
    "        if \"Gyroscope\" in f:\n",
    "            df[\"set\"] = gyr_set\n",
    "            gyr_set += 1\n",
    "            gyr_df = pd.concat([gyr_df, df])\n",
    "\n",
    "    # Convert epoch to datetime index and clean up redundant columns\n",
    "    acc_df.index = pd.to_datetime(acc_df[\"epoch (ms)\"], unit=\"ms\")\n",
    "    gyr_df.index = pd.to_datetime(gyr_df[\"epoch (ms)\"], unit=\"ms\")\n",
    "\n",
    "    del acc_df[\"epoch (ms)\"]\n",
    "    del acc_df[\"time (01:00)\"]\n",
    "    del acc_df[\"elapsed (s)\"]\n",
    "\n",
    "    del gyr_df[\"epoch (ms)\"]\n",
    "    del gyr_df[\"time (01:00)\"]\n",
    "    del gyr_df[\"elapsed (s)\"]\n",
    "\n",
    "    return acc_df, gyr_df\n",
    "\n",
    "# Execute the function\n",
    "acc_df, gyr_df = read_data_from_files(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b35cf",
   "metadata": {},
   "source": [
    "# Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d6b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = pd.concat([acc_df.iloc[:, :3], gyr_df], axis=1)\n",
    "#axis 1 means vertical hai join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b776cf",
   "metadata": {},
   "source": [
    "# Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2483a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.columns = [\n",
    "    \"acc_x\",\n",
    "    \"acc_y\",\n",
    "    \"acc_z\",\n",
    "    \"gyr_x\",\n",
    "    \"gyr_y\",\n",
    "    \"gyr_z\",\n",
    "    \"participant\",\n",
    "    \"label\",\n",
    "    \"category\",\n",
    "    \"set\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259403b",
   "metadata": {},
   "source": [
    "# Resample data (frequency conversion)\n",
    "# Accelerometer:    12.500HZ\n",
    "# Gyroscope:        25.000Hz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a174da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9009 entries, 2019-01-11 15:08:05.200000 to 2019-01-20 17:33:27.800000\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   acc_x        9009 non-null   float64\n",
      " 1   acc_y        9009 non-null   float64\n",
      " 2   acc_z        9009 non-null   float64\n",
      " 3   gyr_x        9009 non-null   float64\n",
      " 4   gyr_y        9009 non-null   float64\n",
      " 5   gyr_z        9009 non-null   float64\n",
      " 6   participant  9009 non-null   object \n",
      " 7   label        9009 non-null   object \n",
      " 8   category     9009 non-null   object \n",
      " 9   set          9009 non-null   int32  \n",
      "dtypes: float64(6), int32(1), object(3)\n",
      "memory usage: 739.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# 1. Define how to aggregate each column\n",
    "# We want the average of sensor data, but the 'last' known label for categories\n",
    "sampling = {\n",
    "    \"acc_x\": \"mean\",\n",
    "    \"acc_y\": \"mean\",\n",
    "    \"acc_z\": \"mean\",\n",
    "    \"gyr_x\": \"mean\",\n",
    "    \"gyr_y\": \"mean\",\n",
    "    \"gyr_z\": \"mean\",\n",
    "    \"participant\": \"last\",\n",
    "    \"label\": \"last\",\n",
    "    \n",
    "    \"category\": \"last\",\n",
    "    \"set\": \"last\",\n",
    "}\n",
    "\n",
    "# 2. Split the master dataframe into a list of dataframes, one for each day\n",
    "# This prevents resampling across the empty gaps at night\n",
    "days = [g for n, g in data_merged.groupby(pd.Grouper(freq=\"D\"))]\n",
    "\n",
    "# 3. Use List Comprehension to resample each day individually\n",
    "# .dropna() removes the empty rows created by pd.Grouper for days with no data\n",
    "data_resampled = pd.concat([\n",
    "    df.resample(rule=\"200ms\").apply(sampling).dropna() \n",
    "    for df in days\n",
    "])\n",
    "data_resampled[\"set\"]=data_resampled[\"set\"].astype(\"int\")\n",
    "# 4. Final check of the new frequency\n",
    "data_resampled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadaf1f7",
   "metadata": {},
   "source": [
    "# Export dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a161375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename at the end of the path\n",
    "data_resampled.to_pickle(r\"C:\\data science\\data-science-template-main\\data\\interim\\01_data_processed.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking-barbell-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
